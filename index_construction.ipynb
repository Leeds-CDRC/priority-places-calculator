{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priority Places Index Construction\n",
    "\n",
    "Depends on data prepared in the data_prep notebook being avialable in the respective data directories defined below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up\n",
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_directory = '/workspaces/priority-places-calculator/data/processed/'\n",
    "raw_data_directory = '/workspaces/priority-places-calculator/data/raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = pd.read_csv(raw_data_directory + 'fsm_lookup/PCD_OA_LSOA_MSOA_LAD_MAY22_UK_LU.csv', encoding='latin-1', usecols=['lsoa11cd', 'pcds', 'ladcd'])\n",
    "lookup['pcds'] = lookup['pcds'].str.replace(' ','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our dataframe of interest via the lookup table\n",
    "df = lookup[['lsoa11cd', 'ladcd']].drop_duplicates()\n",
    "df = df[df['lsoa11cd'].str[0].isin(['E','S','W','9'])]\n",
    "df.set_index('lsoa11cd', inplace=True)\n",
    "\n",
    "# efdi merging\n",
    "efdi = pd.read_csv(data_directory + 'efdi_variables_for_ppfi.csv', index_col=0)\n",
    "df = df.merge(efdi, left_index=True, right_index=True, how='left')\n",
    "\n",
    "# fuel poverty merging\n",
    "fuel_poverty = pd.read_csv(data_directory + 'fuel_poverty.csv', index_col=0)\n",
    "df = df.merge(fuel_poverty, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge':'fuel_merge', 'Percent of households in fuel poverty':'fuel_poverty_pct'}, inplace=True, axis=1)\n",
    "\n",
    "# healthy start voucher uptake\n",
    "hsv = pd.read_csv(data_directory + 'HS_uptake_LSOA.csv')\n",
    "hsv = hsv[~hsv['Uptake (%)'].isna()][['lsoa11cd', 'Uptake (%)']]\n",
    "hsv.set_index('lsoa11cd',inplace=True)\n",
    "df = df.merge(hsv, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'hsv_merge', 'Uptake (%)': 'healthy_start_voucher_uptake'}, inplace=True, axis=1)\n",
    "\n",
    "# Non supermarket distance\n",
    "pcd_nonsupermarket_dist = pd.DataFrame()\n",
    "for f in os.listdir(data_directory):\n",
    "    if f[4:]=='pcd_nonsupermarket_dist.csv':\n",
    "        pcd_nonsupermarket_dist = pd.concat([pcd_nonsupermarket_dist, pd.read_csv(data_directory + f)])\n",
    "pcd_nonsupermarket_dist['PCD'] = pcd_nonsupermarket_dist['PCD'].str.replace(' ','')\n",
    "nonsupermarket_dist = pcd_nonsupermarket_dist.merge(lookup, left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "lsoa_nonsupermarket_dist = nonsupermarket_dist.groupby('lsoa11cd')['0'].mean()\n",
    "df = df.merge(lsoa_nonsupermarket_dist, left_index=True, right_index=True, how='left')\n",
    "df.rename({'0':'nonsupermarket_distance'}, inplace=True, axis=1)\n",
    "\n",
    "# Non supermarket 1km count\n",
    "pcd_nonsupermarket_1kmcount = pd.DataFrame()\n",
    "for f in os.listdir(data_directory):\n",
    "    if f[4:]=='pcd_nonsupermarket_1kmcount.csv':\n",
    "        pcd_nonsupermarket_1kmcount = pd.concat([pcd_nonsupermarket_1kmcount, pd.read_csv(data_directory + f)])\n",
    "pcd_nonsupermarket_1kmcount['PCD'] = pcd_nonsupermarket_1kmcount['Unnamed: 0'].str.replace(' ','')\n",
    "nonsupermarket_1kmcount = pcd_nonsupermarket_1kmcount.merge(lookup, left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "lsoa_nonsupermarket_1kmcount = nonsupermarket_1kmcount.groupby('lsoa11cd')['0'].mean()\n",
    "df = df.merge(lsoa_nonsupermarket_1kmcount, left_index=True, right_index=True, how='left')\n",
    "df.rename({'0':'nonsupermarket_1kmcount'}, inplace=True, axis=1)\n",
    "\n",
    "# prepayment_meters merging\n",
    "prepayment_meters = pd.read_csv(data_directory + 'prepayment_meters.csv', index_col='Lower Layer Super Output Area (LSOA) Code')\n",
    "df = df.merge(prepayment_meters[['Total meters', 'Occupied_Households']], left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'prepayment_merge'}, inplace=True, axis=1)\n",
    "df['prepayment_prevalence'] = df['Total meters'] / df['Occupied_Households']\n",
    "\n",
    "# free school meals\n",
    "fsm_eng = pd.read_csv(data_directory + 'fsm_england.csv', usecols=['lsoa11cd', 'fsm_eligible_percent'])\n",
    "fsm_eng.rename({'fsm_eligible_percent':'fsm_indicator'}, inplace=True, axis=1)\n",
    "fsm_wal = pd.read_csv(data_directory + 'fsm_wales.csv', usecols=['lsoa11cd', 'fsm_eligible_percent'])\n",
    "fsm_wal.rename({'fsm_eligible_percent':'fsm_indicator'}, inplace=True, axis=1)\n",
    "fsm_scot = pd.read_csv(data_directory + 'fsm_scotland.csv', usecols=['lsoa11cd', 'fsm_percent'])\n",
    "fsm_scot.rename({'fsm_percent':'fsm_indicator'}, inplace=True, axis=1)\n",
    "fsm_ni = pd.read_csv(data_directory + 'fsm_ni.csv', usecols=['LSOA11CD', 'prop_FSME_school_leavers'])\n",
    "fsm_ni.rename({'LSOA11CD':'lsoa11cd', 'prop_FSME_school_leavers':'fsm_indicator'}, inplace=True, axis=1)\n",
    "fsm = pd.concat([fsm_eng, fsm_wal, fsm_scot, fsm_ni])\n",
    "fsm.set_index('lsoa11cd', inplace=True)\n",
    "df = df.merge(fsm, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge':'fsm_merge'},axis=1,inplace=True)\n",
    "\n",
    "# Impute prepayment prevalence\n",
    "lad_prepayment_median = df.reset_index()[['index', 'ladcd', 'prepayment_prevalence']].groupby('ladcd')['prepayment_prevalence'].median()\n",
    "df = df.merge(lad_prepayment_median, left_on='ladcd', right_index=True, how='left', suffixes=('', '_lad'))\n",
    "df['prepayment_prevalence'] = df['prepayment_prevalence'].fillna(df['prepayment_prevalence_lad'])\n",
    "\n",
    "# Food bank distance merging\n",
    "foodbank_distance = pd.read_csv(data_directory + 'postcode_to_nearest_foodbank_distance.csv')\n",
    "foodbank_distance['PCD'] = foodbank_distance['PCD'].str.replace(' ','')\n",
    "foodbank_distance = foodbank_distance.merge(lookup[['pcds', 'lsoa11cd']], left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "foodbank_distance = foodbank_distance.groupby('lsoa11cd')['0'].mean()\n",
    "df = df.merge(foodbank_distance, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'foodbank_distance_merge', '0': 'foodbank_distance'}, inplace=True, axis=1)\n",
    "\n",
    "#market_distance\n",
    "market_distance = pd.read_csv(data_directory + 'pcd_nmftmarkets_dist.csv')\n",
    "market_distance['PCD'] = market_distance['PCD'].str.replace(' ','')\n",
    "market_distance = market_distance.merge(lookup[['pcds', 'lsoa11cd']], left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "market_distance = market_distance.groupby('lsoa11cd')['0'].mean()\n",
    "market_distance = market_distance.reset_index()\n",
    "# Exclude Scotland and NI - the data coverage isn't good enough\n",
    "market_distance = market_distance[~market_distance['lsoa11cd'].str[0].isin(['9', 'S'])]\n",
    "df = df.merge(market_distance.set_index('lsoa11cd'), left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'market_distance_merge', '0': 'market_distance'}, inplace=True, axis=1)\n",
    "\n",
    "# market 1km count\n",
    "market_1km_count = pd.read_csv(data_directory + 'postcode_market_1km_count.csv')\n",
    "market_1km_count['PCD'] = market_1km_count['PCD'].str.replace(' ','')\n",
    "market_1km_count = market_1km_count.merge(lookup[['pcds', 'lsoa11cd']], left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "market_1km_count = market_1km_count.groupby('lsoa11cd')['overlap_count'].mean()\n",
    "market_1km_count = market_1km_count.reset_index()\n",
    "# Exclude Scotland and NI - the data coverage isn't good enough\n",
    "market_1km_count = market_1km_count[~market_1km_count['lsoa11cd'].str[0].isin(['9', 'S'])]\n",
    "df = df.merge(market_1km_count.set_index('lsoa11cd'), left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'market_1km_count_merge', 'overlap_count': 'market_1km_count'}, inplace=True, axis=1)\n",
    "\n",
    "# large supermarket distance\n",
    "supermarket_distance = pd.read_csv(data_directory + 'postcode_to_nearest_large_supermarket_distance.csv')\n",
    "supermarket_distance['PCD'] = supermarket_distance['PCD'].str.replace(' ','')\n",
    "supermarket_distance = supermarket_distance.merge(lookup[['pcds', 'lsoa11cd']], left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "supermarket_distance = supermarket_distance.groupby('lsoa11cd')['0'].mean()\n",
    "df = df.merge(supermarket_distance, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'supermarket_distance_merge', '0': 'supermarket_distance'}, inplace=True, axis=1)\n",
    "\n",
    "# supermarket 1km count\n",
    "supermarket_1kmcount = pd.read_csv(data_directory + 'postcode_to_nearest_large_supermarket_1km_count.csv', usecols=['PCD', 'overlap_count'])\n",
    "supermarket_1kmcount['PCD'] = supermarket_1kmcount['PCD'].str.replace(' ','')\n",
    "supermarket_1kmcount = supermarket_1kmcount.merge(lookup[['pcds', 'lsoa11cd']], left_on='PCD', right_on='pcds', how='left', indicator=True)\n",
    "supermarket_1kmcount = supermarket_1kmcount.groupby('lsoa11cd')['overlap_count'].mean()\n",
    "df = df.merge(supermarket_1kmcount, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'supermarket_1kmcount_merge', 'overlap_count': 'supermarket_1kmcount'}, inplace=True, axis=1)\n",
    "\n",
    "# Propensity shop online\n",
    "online_propensity = pd.read_csv(data_directory + 'propensity_shop_online.csv')\n",
    "online_propensity.set_index('LSOA11CD', inplace=True)\n",
    "df = df.merge(online_propensity, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'online_propensity_merge', 'zshoponline': 'online_propensity'},inplace=True, axis=1)\n",
    "\n",
    "# inc_dep\n",
    "inc_dep_eng = pd.read_csv(data_directory + 'inc_dep_england.csv', index_col=0)\n",
    "inc_dep_ni = pd.read_csv(data_directory + 'inc_dep_ni.csv', index_col=0)\n",
    "inc_dep_ni.rename({ \"Proportion of the population living in households whose equivalised income is below 60 per cent of the NI median \\n(%)\":\"inc_dep_indicator\"}, inplace=True, axis=1)\n",
    "inc_dep_scotland = pd.read_csv(data_directory + 'inc_dep_scotland.csv', index_col=0)\n",
    "inc_dep_scotland.rename({\"Income_rate\":\"inc_dep_indicator\"}, inplace=True, axis=1)\n",
    "inc_dep_scotland['inc_dep_indicator'] = pd.to_numeric(inc_dep_scotland.replace(\"*\", pd.to_numeric(inc_dep_scotland[inc_dep_scotland['inc_dep_indicator']!=\"*\"]['inc_dep_indicator']).mean())['inc_dep_indicator'])\n",
    "inc_dep_wal = pd.read_csv(data_directory + 'inc_dep_wal.csv', index_col=0)\n",
    "inc_dep_wal.rename({\"People in Income Deprivation (%)\":\"inc_dep_indicator\"}, inplace=True, axis=1)\n",
    "inc_dep_wal['inc_dep_indicator'] = inc_dep_wal['inc_dep_indicator'] / 100.0\n",
    "inc_dep = pd.concat([inc_dep_eng, inc_dep_ni, inc_dep_scotland, inc_dep_wal])\n",
    "df = df.merge(inc_dep, left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'inc_dep_merge'},inplace=True, axis=1)\n",
    "\n",
    "# Car access\n",
    "car = pd.read_csv(data_directory + 'car_access.csv')\n",
    "car['no_car_indicator'] = car['no_cars_in_household'] / car['households']\n",
    "car.set_index('geo_code', inplace=True)\n",
    "df = df.merge(car['no_car_indicator'], left_index=True, right_index=True, how='left', indicator=True)\n",
    "df.rename({'_merge': 'car_merge'},inplace=True, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_cols = [\n",
    "    # Proximity to and density of retail facilities\n",
    "    'supermarket_1kmcount', \n",
    "    'supermarket_distance', \n",
    "    \n",
    "    # Transport to and accessibility of grocery retail facilities\n",
    "    'AccessibilityViaPublicTransport', \n",
    "    'AverageTravelDistance', \n",
    "    \n",
    "    # E-commerce access\n",
    "    'online_propensity', \n",
    "    'OnlineGroceryAvailability', \n",
    "    \n",
    "    # Neighbourhood socio-economic and demographic\n",
    "    'no_car_indicator', \n",
    "    'inc_dep_indicator', \n",
    "    \n",
    "    # Proximity to and density of non-supermarket food provision\n",
    "    'nonsupermarket_distance',\n",
    "    'nonsupermarket_1kmcount',\n",
    "    'market_1km_count', \n",
    "    'market_distance', \n",
    "    \n",
    "    # Food for families\n",
    "    'fsm_indicator',\n",
    "    'healthy_start_voucher_uptake', \n",
    "    'foodbank_distance', \n",
    "    \n",
    "    #Fuel poverty pressures\n",
    "    'fuel_poverty_pct',\n",
    "    'prepayment_prevalence']\n",
    "\n",
    "priority_places = df[indicator_cols].copy()\n",
    "\n",
    "priority_places = priority_places.drop_duplicates()\n",
    "\n",
    "# Drop Isles of Scilly\n",
    "priority_places.drop('E01019077', inplace=True)\n",
    "\n",
    "# The first task is to orient each indicator in the correct direction\n",
    "# i.e. so that high values correspond to higher priority places\n",
    "priority_places = pd.concat([1 * priority_places[[\n",
    "                    'supermarket_distance', \n",
    "                    'AccessibilityViaPublicTransport', \n",
    "                    'AverageTravelDistance', \n",
    "                    'no_car_indicator', \n",
    "                    'inc_dep_indicator', \n",
    "                    'market_distance', \n",
    "                    'fuel_poverty_pct', \n",
    "                    'prepayment_prevalence', \n",
    "                    'nonsupermarket_distance', \n",
    "                    'fsm_indicator', \n",
    "                    'healthy_start_voucher_uptake']], \n",
    "                  -1 * priority_places[[\n",
    "                      'foodbank_distance', \n",
    "                      'supermarket_1kmcount', \n",
    "                      'online_propensity', \n",
    "                      'OnlineGroceryAvailability', \n",
    "                      'market_1km_count', \n",
    "                      'nonsupermarket_1kmcount']]], axis=1)\n",
    "\n",
    "# Find our country-level denominators\n",
    "priority_places['country'] = priority_places.index.str[0]\n",
    "country_counts = priority_places.reset_index().groupby('country')['index'].count()\n",
    "priority_places = priority_places.merge(country_counts, left_on='country', right_index=True, how='inner')\n",
    "priority_places.rename({'index': 'country_denominator'}, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Perform ranking of each indicator\n",
    "priority_places.fillna(0, inplace=True)\n",
    "priority_places_ranked = priority_places.groupby('country').rank(method='min', ascending=False).astype(int)\n",
    "\n",
    "for c in priority_places_ranked[indicator_cols].columns: \n",
    "    priority_places_ranked[c] = (priority_places_ranked[c] - 0.5) / priority_places['country_denominator']\n",
    "    priority_places_ranked[c] = sp.stats.norm.ppf(priority_places_ranked[c],loc=0,scale=1)\n",
    "    \n",
    "priority_places_ranked['country'] = priority_places_ranked.index.str[0]\n",
    "\n",
    "#Combine transformed indicators into domains\n",
    "priority_places_ranked['domain_supermarket_proximity'] = 0.5 * priority_places_ranked[['supermarket_distance', 'supermarket_1kmcount']].sum(axis=1)\n",
    "priority_places_ranked['domain_supermarket_accessibility'] = 0.5 * priority_places_ranked[['AccessibilityViaPublicTransport', 'AverageTravelDistance']].sum(axis=1)\n",
    "priority_places_ranked['domain_ecommerce_access'] = 0.5 * priority_places_ranked[['online_propensity', 'OnlineGroceryAvailability']].sum(axis=1)\n",
    "priority_places_ranked['domain_socio_demographic'] = (1./2.) * priority_places_ranked[[ 'no_car_indicator', 'inc_dep_indicator']].sum(axis=1)\n",
    "priority_places_ranked['domain_nonsupermarket_proximity'] = (1./4.) * priority_places_ranked[['nonsupermarket_distance','nonsupermarket_1kmcount','market_1km_count', 'market_distance']].sum(axis=1)\n",
    "priority_places_ranked['domain_food_for_families'] = (1./4.) * priority_places_ranked[['foodbank_distance', 'healthy_start_voucher_uptake', 'fsm_indicator']].sum(axis=1)\n",
    "priority_places_ranked['domain_fuel_poverty'] = 0.5 * priority_places_ranked[['fuel_poverty_pct','prepayment_prevalence']].sum(axis=1)\n",
    "\n",
    "domain_columns = ['domain_supermarket_proximity', \n",
    "                  'domain_supermarket_accessibility', \n",
    "                  'domain_ecommerce_access', \n",
    "                  'domain_socio_demographic', \n",
    "                  'domain_nonsupermarket_proximity', \n",
    "                  'domain_food_for_families', \n",
    "                  'domain_fuel_poverty']\n",
    "\n",
    "# Rank the domains\n",
    "priority_places_domains = priority_places_ranked[domain_columns + ['country']].groupby('country').rank(method='min').astype(int)\n",
    "priority_places_domains['country'] = priority_places_domains.index.str[0]\n",
    "\n",
    "priority_places_domains = priority_places_domains.merge(country_counts, left_on='country', right_index=True, how='inner')\n",
    "priority_places_domains.rename({'index': 'country_denominator'}, inplace=True, axis=1)\n",
    "\n",
    "priority_places_domains_normalised = pd.DataFrame(columns=priority_places_domains[domain_columns].columns)\n",
    "for c in priority_places_domains[domain_columns].columns:\n",
    "    priority_places_domains_normalised[c] = -23 * np.log(1 - (priority_places_domains[c] / priority_places_domains['country_denominator']) * (1 - np.exp(- 100 / 23)))\n",
    "\n",
    "priority_places_domains['combined'] = (1./8.) * priority_places_domains_normalised['domain_supermarket_proximity'] + \\\n",
    "(1./8.) * priority_places_domains_normalised['domain_supermarket_accessibility'] + \\\n",
    "(1./8.) * priority_places_domains_normalised['domain_ecommerce_access'] + \\\n",
    "(1./8.) * priority_places_domains_normalised['domain_nonsupermarket_proximity'] + \\\n",
    "(1./6.) * priority_places_domains_normalised['domain_socio_demographic'] + \\\n",
    "(1./6.) * priority_places_domains_normalised['domain_food_for_families'] + \\\n",
    "(1./6.) * priority_places_domains_normalised['domain_fuel_poverty']\n",
    "\n",
    "priority_places_domains['combined'] = priority_places_domains[['country', 'combined']].groupby('country').rank(method='min').astype(int)\n",
    "\n",
    "priority_places_deciles = priority_places_domains.copy()\n",
    "for country in ['E', 'S', 'W', '9']:\n",
    "    for col in domain_columns + ['combined']:\n",
    "        if country == '9' and col in ['domain_ecommerce_access', 'domain_supermarket_accessibility', 'domain_fuel_poverty']:\n",
    "            priority_places_deciles.loc[priority_places_deciles['country']==country, col] = 0\n",
    "        else:\n",
    "            priority_places_deciles.loc[priority_places_deciles['country']==country, col] = pd.to_numeric(pd.qcut(priority_places_domains.loc[priority_places_deciles['country']==country, col], 10, duplicates='drop', labels=range(1,11)))\n",
    "            \n",
    "priority_places_full = priority_places_domains.merge(priority_places_deciles, left_index=True, right_index=True, suffixes=('', '_decile'))\n",
    "priority_places_full.drop(['country_decile', 'country_denominator_decile'], axis=1, inplace=True)           \n",
    "\n",
    "priority_places_full.loc[priority_places.index.str.startswith('9'), \n",
    "                        ['domain_supermarket_accessibility', \n",
    "                         'domain_ecommerce_access', \n",
    "                         'domain_fuel_poverty', \n",
    "                         'domain_supermarket_accessibility_decile', \n",
    "                         'domain_ecommerce_access_decile', \n",
    "                         'domain_fuel_poverty_decile']] = pd.NA\n",
    "\n",
    "# Rename decile columns to align with original field names\n",
    "priority_places_full.rename({'domain_supermarket_proximity_decile': 'pp_dec_domain_supermarket_proximity',\n",
    "                             'domain_supermarket_accessibility_decile': 'pp_dec_domain_supermarket_accessibility',\n",
    "                             'domain_ecommerce_access_decile': 'pp_dec_domain_ecommerce_access',\n",
    "                             'domain_socio_demographic_decile': 'pp_dec_domain_socio_demographic',\n",
    "                             'domain_nonsupermarket_proximity_decile': 'pp_dec_domain_nonsupermarket_proximity',\n",
    "                             'domain_food_for_families_decile': 'pp_dec_domain_food_for_families',\n",
    "                             'domain_fuel_poverty_decile': 'pp_dec_domain_fuel_poverty',\n",
    "                             'combined_decile': 'pp_dec_combined'}, inplace=True, axis=1)\n",
    "\n",
    "priority_places_full.loc[priority_places.index.str.startswith('9'), ['country']] = 'NI'\n",
    "\n",
    "priority_places_full.to_csv('priority_places_index_created_%s.csv' % datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce weighting on accessibility domains to test London specific version of the index\n",
    "priority_places_domains['combined'] = (1./12.) * priority_places_domains_normalised['domain_supermarket_proximity'] + \\\n",
    "(1./12.) * priority_places_domains_normalised['domain_supermarket_accessibility'] + \\\n",
    "(1./12.) * priority_places_domains_normalised['domain_ecommerce_access'] + \\\n",
    "(1./12.) * priority_places_domains_normalised['domain_nonsupermarket_proximity'] + \\\n",
    "(2./9.) * priority_places_domains_normalised['domain_socio_demographic'] + \\\n",
    "(2./9.) * priority_places_domains_normalised['domain_food_for_families'] + \\\n",
    "(2./9.) * priority_places_domains_normalised['domain_fuel_poverty']\n",
    "\n",
    "priority_places_domains['combined'] = priority_places_domains[['country', 'combined']].groupby('country').rank(method='min').astype(int)\n",
    "\n",
    "priority_places_deciles = priority_places_domains.copy()\n",
    "for country in ['E', 'S', 'W', '9']:\n",
    "    for col in domain_columns + ['combined']:\n",
    "        if country == '9' and col in ['domain_ecommerce_access', 'domain_supermarket_accessibility', 'domain_fuel_poverty']:\n",
    "            priority_places_deciles.loc[priority_places_deciles['country']==country, col] = 0\n",
    "        else:\n",
    "            priority_places_deciles.loc[priority_places_deciles['country']==country, col] = pd.to_numeric(pd.qcut(priority_places_domains.loc[priority_places_deciles['country']==country, col], 10, duplicates='drop', labels=range(1,11)))\n",
    "            \n",
    "priority_places_full = priority_places_domains.merge(priority_places_deciles, left_index=True, right_index=True, suffixes=('', '_decile'))\n",
    "priority_places_full.drop(['country_decile', 'country_denominator_decile'], axis=1, inplace=True)           \n",
    "\n",
    "priority_places_full.loc[priority_places.index.str.startswith('9'), \n",
    "                        ['domain_supermarket_accessibility', \n",
    "                         'domain_ecommerce_access', \n",
    "                         'domain_fuel_poverty', \n",
    "                         'domain_supermarket_accessibility_decile', \n",
    "                         'domain_domain_ecommerce_access_decile', \n",
    "                         'domain_fuel_poverty_decile']] = pd.NA\n",
    "\n",
    "priority_places_full.loc[priority_places.index.str.startswith('9'), ['country']] = 'NI'\n",
    "\n",
    "priority_places_full.to_csv(data_directory + 'priority_places_london_weighting.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
